Learning Objectives:-
Create a PersistentVolume
Create a PersistentVolumeClaim
Create a MySQL Pod configured to use the PersistentVolumeClaim

Problem Statement:-
Your company needs a small database server to support a new application. They have asked you to deploy a pod running a MySQL container, but they want the data to persist even if the pod is deleted or replaced. Therefore, the MySQL database pod requires persistent storage.


You will need to do the following:-

1. Create a PersistentVolume:
	The PersistentVolume should be named mysql-pv.
	The volume needs a capacity of 1Gi.
	Use a storageClassName of localdisk.
	Use the accessMode ReadWriteOnce.
	Store the data locally on the node using a hostPath volume at the location /mnt/data.

2. Create a PersistentVolumeClaim:
	The PersistentVolumeClaim should be named mysql-pv-claim.
	Set a resource request on the claim for 500Mi of storage.
	Use the same storageClassName and accessModes as the PersistentVolume so that this claim can bind to the PersistentVolume.

3. Create a MySQL Pod configured to use the PersistentVolumeClaim:
	The Pod should be named mysql-pod.
	Use the image mysql:5.6.
	Expose the containerPort 3306.
	Set an environment variable called MYSQL_ROOT_PASSWORD with the value password.
	Add the PersistentVolumeClaim as a volume and mount it to the container at the path /var/lib/mysql.

===========================================================

1. Create a PersistentVolume:
The PersistentVolume should be named mysql-pv.
The volume needs a capacity of 1Gi.
Use a storageClassName of localdisk.
Use the accessMode ReadWriteOnce.
Store the data locally on the node using a hostPath volume at the location /mnt/data.


Solustion :

vi pv.yaml
cat pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mysql-pv
  labels:
    app: mysql
spec:
  capacity:
    storage: 1Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: localdisk
  local:
    path: /mnt/data
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - worker2



[ec2-user@master1 ~]$ kubectl create -f pv.yaml
persistentvolume/mysql-pv created
[ec2-user@master1 ~]$

[ec2-user@master1 ~]$ kubectl get pv
NAME               CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS    REASON   AGE
mysql-pv            1Gi       RWO            Retain           Available            localdisk               10s
[ec2-user@master1 ~]$

ec2-user@master1 ~]$ kubectl describe pv mysql-local-pv
Name:              mysql-pv
Labels:            app=/mnt
Annotations:       <none>
Finalizers:        [kubernetes.io/pv-protection]
StorageClass:      localdisk
Status:            Available
Claim:
Reclaim Policy:    Retain
Access Modes:      RWO
VolumeMode:        Filesystem
Capacity:          1Gi
Node Affinity:
  Required Terms:
    Term 0:        kubernetes.io/hostname in [worker2]
Message:
Source:
    Type:  LocalVolume (a persistent volume backed by local storage on a node)
    Path:  /mnt/data
Events:    <none>
[ec2-user@master1 ~]$

===================================================================================
2. Create a PersistentVolumeClaim:
The PersistentVolumeClaim should be named mysql-pv-claim.
Set a resource request on the claim for 500Mi of storage.
Use the same storageClassName and accessModes as the PersistentVolume so that this claim can bind to the PersistentVolume.

Solustion :

---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: mysql-pv-claim
  labels:
    app: mysql
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: localdisk
  resources:
    requests:
      storage: 500Mi
  selector:
    matchLabels:
      app: mysql


[ec2-user@master1 ~]$ kubectl apply -f mypvc.yaml -n myk8sql
persistentvolumeclaim/mysql-pv-claim created
[ec2-user@master1 ~]$


[ec2-user@master1 ~]$ kubectl get pvc -n myk8sql
NAME                  STATUS   VOLUME       CAPACITY   ACCESS MODES   STORAGECLASS    AGE
mysql-pv-claim       Bound    mysql-pv      500Mi       RWO            localdisk      7s
[ec2-user@master1 ~]$

=========================================================================================

3. Create a MySQL Pod configured to use the PersistentVolumeClaim:
The Pod should be named mysql-pod.
Use the image mysql:5.6.
Expose the containerPort 3306.
Set an environment variable called MYSQL_ROOT_PASSWORD with the value password.
Add the PersistentVolumeClaim as a volume and mount it to the container at the path /var/lib/mysql.


Solustion ::

---
apiVersion: v1
kind: Service
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  ports:
    - port: 3306
  selector:
    app: mysql
    tier: mysql
  type: NodePort
---
apiVersion: v1
kind: Secret
metadata:
  name: mysql-pass
stringData:
  password: admin123
---
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: pod
metadata:
  name: mysql-pod
  labels:
    app: mysql
spec:
  selector:
    matchLabels:
      app: mysql
      tier: mysql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: mysql
        tier: mysql
    spec:
      containers:
      - image: mysql:5.6
        name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: password
        ports:
        - containerPort: 3306
          name: mysql
        volumeMounts:
        - name: mysql-pv
          mountPath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentVolumeClaim:
          claimName: mysql-pv-claim
      nodeSelector:
        kubernetes.io/hostname: worker2


[ec2-user@master1 kubernetes-installation]$ kubectl get nodes
NAME      STATUS     ROLES    AGE     VERSION
master1   Ready      master   3d10h   v1.18.3
worker1   Ready      <none>   3d10h   v1.18.3
worker2   Ready      <none>   32h     v1.18.3
[ec2-user@master1 kubernetes-installation]$


[ec2-user@master1 kubernetes-installation]$ kubectl create -f mysql.yaml
persistentvolume/mysql-pv created
persistentvolumeclaim/mysql-pv-claim created
service/mysql created
secret/mysql-pass created
pod.apps/mysql created

[ec2-user@master1 kubernetes-installation]$ kubectl get pod -l app=mysql
NAME              READY   UP-TO-DATE   AVAILABLE   AGE
mysql    1/1         1            1        26s

[ec2-user@master1 kubernetes-installation]$ kubectl get svc -l app=mysql
NAME              TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
mysql            NodePort   10.108.103.177     <none>       3306:31527/TCP   55s

[ec2-user@master1 kubernetes-installation]$ kubectl get pods -l app=mysql
NAME                               READY   STATUS    RESTARTS   AGE
mysql-57585db5c6-sjzgz             1/1     Running   0          71s
[ec2-user@master1 kubernetes-installation]$


Note: Here is the Mysql is installed successfully as per requirement !! 


==================================================


On Worker Node - 2 Follow the below activity

[ec2-user@master1 ~]$ kubectl get pv
No resources found in dvsdevops namespace.
[ec2-user@master1 ~]$ cd kubernetes-installation/
[ec2-user@master1 kubernetes-installation]$ ssh -i mykey.pem ec2-user@worker2
Last login: Wed Jun  3 18:27:26 2020 from master1.us-central1-a.c.deep-voyage-276711.internal
[ec2-user@worker2 ~]$
[ec2-user@worker2 ~]$
[ec2-user@worker2 ~]$
[ec2-user@worker2 ~]$ sudo su -
Last login: Wed Jun  8 18:27:29 UTC 2020 on pts/1
[root@worker2 ~]#

[root@worker2 ~]# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   50G  0 disk
├─sda1   8:1    0  200M  0 part /boot/efi
└─sda2   8:2    0 49.8G  0 part /
sdb      8:16   0   50G  0 disk

[root@worker2 ~]# vgcreate myvg /dev/sdb
  Physical volume "/dev/sdb" successfully created.
  Volume group "myvg" successfully created

[root@worker2 ~]# vgs
  VG   #PV #LV #SN Attr   VSize   VFree
  myvg   1   0   0 wz--n- <50.00g <50.00g

[root@worker2 ~]# lvcreate -L +3G -n mylv myvg
  Logical volume "mylv" created.

[root@worker2 ~]# lvs
  LV   VG   Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  mylv myvg -wi-a----- 30.00g

[root@worker2 ~]# mkfs.ext4 /dev/myvg/mylv
mke2fs 1.42.9 (28-Dec-2013)
Discarding device blocks: done
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
Stride=0 blocks, Stripe width=0 blocks
1966080 inodes, 7864320 blocks
393216 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=2155872256
240 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks:
        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,
        4096000

Allocating group tables: done
Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

[root@worker2 ~]#
[root@worker2 ~]# mkdir /mnt/data

[root@worker2 ~]# mount -t ext4 /dev/myvg/mylv /mnt/data

[root@worker2 ~]# df -hT /mnt/data
Filesystem            Type  Size  Used Avail Use% Mounted on
/dev/mapper/myvg-mylv ext4   30G   45M   28G   1% /mnt/data

[root@worker2 ~]# vi /etc/fstab
[root@worker2 ~]# mount -a

[root@worker2 ~]# df -hT /mnt/data
Filesystem            Type  Size  Used Avail Use% Mounted on
/dev/mapper/myvg-mylv ext4   3G   45M   2.5G   1% /mnt/data
[root@worker2 ~]# logout
[ec2-user@worker2 ~]$ logout
Connection to worker2 closed.
[ec2-user@master1 kubernetes-installation]$